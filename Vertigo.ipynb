{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "\n",
    "p=Perceptron()\n",
    "classes = []\n",
    "data = []\n",
    "sublists = []\n",
    "\n",
    "with open('vertigo_train.txt', 'r') as f:\n",
    "    t = f.read().splitlines()\n",
    "    for lines in t:\n",
    "        sublists.append(lines[2:].replace(\" \", \",\")) \n",
    "    \n",
    "for line in t:\n",
    "    classes.append(int(line[0]))\n",
    "    \n",
    "elems=[]\n",
    "for line in sublists:\n",
    "    line.replace(\",\",\"\")\n",
    "    for elem in line.replace(\",\",\"\"):\n",
    "        elems.append(int(elem))\n",
    "\n",
    "data = np.array_split(elems, len(t))\n",
    "\n",
    "p.fit(data,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 3, 3, 5, 3, 3, 3, 1, 6, 3, 3, 2, 3, 3, 2, 3, 1, 2, 1, 3, 3,\n",
       "       5, 2, 5, 2, 6, 4, 1, 3, 3, 1, 5, 5, 6, 2, 3, 3, 5, 1, 6, 3, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 1, 1, 3, 1, 3, 6, 3, 3, 3, 5, 3, 3, 3, 3, 3, 1,\n",
       "       3, 6, 2, 3, 3, 5, 6, 3, 3, 6, 3, 3, 6, 3, 2, 3, 3, 3, 3, 3, 3, 5,\n",
       "       2, 3, 2, 2, 5, 3, 3, 3, 5, 5, 4, 3, 3, 5, 3, 3, 2, 6, 3, 2, 5, 5,\n",
       "       3, 3, 6, 3, 3, 2, 1, 3, 3, 6, 3, 6, 2, 3, 3, 3, 6, 1, 1, 3, 5, 3,\n",
       "       5, 2, 5, 6, 1, 1, 1, 3, 3, 6, 2, 3, 4, 3, 1, 2, 2, 3, 5, 2, 3, 3,\n",
       "       3, 1, 3, 3, 3, 1, 3, 2, 1, 6, 3, 3, 5, 1, 2, 1, 3, 3, 3, 2, 1, 6,\n",
       "       3, 5, 1, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 1, 2, 6, 3, 3])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telems = []\n",
    "tdata = []\n",
    "cor = []\n",
    "\n",
    "\n",
    "with open('vertigo_answers.txt', 'r') as f:\n",
    "    a = f.read().splitlines()\n",
    "    \n",
    "with open('vertigo_predict.txt', 'r') as f:\n",
    "    l = f.read().splitlines()\n",
    "    for lines in l:\n",
    "        for elem in lines.replace(\" \",\"\"):\n",
    "            telems.append(int(elem))\n",
    "tdata = np.array_split(telems, len(l))\n",
    "\n",
    "for item in a:\n",
    "    cor.append(int(item))\n",
    "cor = np.array(cor)\n",
    "pre = p.predict(tdata)\n",
    "pre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percepton (max_iter = 10):  74.0 % correct\n",
      "Percepton (max_iter = 50):  80.0 % correct\n",
      "Percepton (max_iter = 100):  80.0 % correct\n",
      "Percepton (max_iter = 250):  80.0 % correct\n",
      "Percepton (max_iter = 500):  80.0 % correct\n",
      "Percepton (max_iter = 1000):  80.0 % correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armerila/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "def predict(n):\n",
    "    p=Perceptron(max_iter = n)\n",
    "    p.fit(data,classes)\n",
    "    pre = p.predict(tdata)\n",
    "    percentage = np.sum(pre == cor) / len(pre)\n",
    "    print((\"Percepton (max_iter = {}): \").format(n),percentage.round(2)*100,(\"% correct\"))\n",
    "\n",
    "predict(10)\n",
    "predict(50)\n",
    "predict(100)\n",
    "predict(250)\n",
    "predict(500)\n",
    "predict(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbour:  61.0 % correct\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "neigh.fit(data, classes) \n",
    "KNeighborsRegressor(...)\n",
    "preneigh = neigh.predict(tdata)\n",
    "\n",
    "percentage = np.sum(preneigh == cor) / len(preneigh)\n",
    "print(\"Nearest neighbour: \",percentage.round(2)*100,(\"% correct\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
